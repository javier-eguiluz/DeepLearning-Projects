{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4iDat0AWkYtw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating a Neural Network for handwritten Digit Recognition with PyTorch**"
      ],
      "metadata": {
        "id": "ynUvKvOQikPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: Javier Eguíluz Romero"
      ],
      "metadata": {
        "id": "AHiCM-QZkO0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the code to create and train an quick neural network that reads images of handwritten digits (from the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)) and gets the actual number. Prior to the data loading and training there're some definitions of functions that will help with the processes.\n",
        "\n"
      ],
      "metadata": {
        "id": "DPWD-IM8N1sp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and Settings"
      ],
      "metadata": {
        "id": "4iDat0AWkYtw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sCCneT_mSEhz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "a_q_8V1EYhTa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function definitions"
      ],
      "metadata": {
        "id": "cw3E1X53lBcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definition of the Neural Network"
      ],
      "metadata": {
        "id": "L1PT6oG4lW5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture of the NN. Three linear layers with ReLU activation functions.\n",
        "\n",
        "class MNIST_NN(nn.Module):\n",
        "  def __init__(self, size_input, size_output):\n",
        "    super(MNIST_NN, self).__init__()\n",
        "    self.fc1 = nn.Linear(size_input, 400)\n",
        "    self.rel1 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(400, 50)\n",
        "    self.rel2 = nn.ReLU()\n",
        "    self.fc3 = nn.Linear(50,size_output)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.rel1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.rel2(x)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "D9ARxzvLOG5r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "K87KRLxElj4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads the data from the MNIST dataset and prepares it in batches of size \"batch_size\". If \"train_bool\" is true, it retrieves the training data, otherwise it gets the testing data.\n",
        "def LoadData(batch_size, train_bool=True):\n",
        "  data = DataLoader(\n",
        "      datasets.MNIST(root='dataset/', train=train_bool, transform=transforms.ToTensor(), download=True),\n",
        "      batch_size=batch_size, \n",
        "      shuffle=True)    \n",
        "  return data"
      ],
      "metadata": {
        "id": "k-zxO0mvS__m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains the NN taking the training data through as many epochs as defined. The backward method can be changed.\n",
        "def train(data_train, model, criterion, optimizer, epochs):\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    for data, targets in data_train:\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "      data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "      # forward\n",
        "      scores = model(data)\n",
        "      loss = criterion(scores, targets)\n",
        "\n",
        "      #backward\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ],
      "metadata": {
        "id": "93ngcsNO-bW_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Provides with the performance of the model via the parameters: Precision, Recall and the F1 score for each one of the classes.\n",
        "def performance_metrics(model, dataset):\n",
        "  true_positives = [0]*10\n",
        "  false_negatives = [0]*10\n",
        "  false_positives = [0]*10\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data, targets in dataset:\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "      data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "      scores = model(data)\n",
        "      _, predicted = scores.max(1)\n",
        "\n",
        "      for i in range(targets.size()[0]):\n",
        "        actual_value = targets[i]\n",
        "        predicted_value = predicted[i]\n",
        "\n",
        "        if predicted_value == actual_value:\n",
        "          true_positives[actual_value] += 1\n",
        "        else:\n",
        "          false_negatives[actual_value] += 1\n",
        "          false_positives[predicted_value] += 1\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  #precision\n",
        "  precision = np.divide( true_positives, np.add(true_positives,false_positives) )\n",
        "  #recall\n",
        "  recall = np.divide( true_positives, np.add(true_positives,false_negatives) )\n",
        "  #F1 Score\n",
        "  F1_score = 2*np.divide( np.multiply(precision,recall), np.add(precision,recall) )\n",
        "\n",
        "  return precision, recall, F1_score"
      ],
      "metadata": {
        "id": "ye2NYH7itg-2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and evaluation of the Neural Network"
      ],
      "metadata": {
        "id": "zUnwvJ9rlr7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the data from the MNIST Dataset"
      ],
      "metadata": {
        "id": "nmhQuphGl4ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition of parameters.\n",
        "batch_size = 64\n",
        "size_input = 28*28\n",
        "size_output = 10\n",
        "learning_rate = 0.001\n",
        "epochs = 2"
      ],
      "metadata": {
        "id": "c0Mkg7PXM405"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data.\n",
        "train_data = LoadData(batch_size, train_bool=True)\n",
        "test_data = LoadData(batch_size, train_bool=False)"
      ],
      "metadata": {
        "id": "mf1im6HZURMB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training of the model"
      ],
      "metadata": {
        "id": "UICGHf3-mBbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify and train the model\n",
        "model = MNIST_NN(size_input, size_output).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train(train_data, model, criterion, optimizer, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpqdW7gHUWZL",
        "outputId": "eac6e14b-7a89-4e71-f39a-993ce2fbd823"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:27<00:00, 13.86s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing of the model"
      ],
      "metadata": {
        "id": "tQduLfCbmHVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the performance\n",
        "precision, recall, F1_score = performance_metrics(model,test_data)\n",
        "print(f'The performance of the model on the test data gives these averaged values: Precision: {np.mean(precision)*100:.2f}%, Recall: {np.mean(recall)*100:.2f}%, F1 score: {np.mean(F1_score):.4f}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KitX8x3yxYZs",
        "outputId": "b473fe5c-25ab-4a6c-e615-63937b99d5b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The performance of the model on the test data gives these averaged values: Precision: 97.17%, Recall: 97.16%, F1 score: 0.9716.\n"
          ]
        }
      ]
    }
  ]
}