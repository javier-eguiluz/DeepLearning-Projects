{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating a Neural Network for handwritten Digit Recognition with PyTorch**"
      ],
      "metadata": {
        "id": "ynUvKvOQikPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: Javier Eguíluz Romero"
      ],
      "metadata": {
        "id": "AHiCM-QZkO0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and Settings"
      ],
      "metadata": {
        "id": "4iDat0AWkYtw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sCCneT_mSEhz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "a_q_8V1EYhTa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function definitions"
      ],
      "metadata": {
        "id": "cw3E1X53lBcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definition of the Neural Network"
      ],
      "metadata": {
        "id": "L1PT6oG4lW5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_NN(nn.Module):\n",
        "  def __init__(self, size_input, size_output):\n",
        "    super(MNIST_NN, self).__init__()\n",
        "    self.fc1 = nn.Linear(size_input, 400)\n",
        "    self.rel1 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(400, 50)\n",
        "    self.rel2 = nn.ReLU()\n",
        "    self.fc3 = nn.Linear(50,size_output)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.rel1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.rel2(x)\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "D9ARxzvLOG5r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "K87KRLxElj4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LoadData(batch_size, train_bool=True):\n",
        "  data = DataLoader(\n",
        "      datasets.MNIST(root='dataset/', train=train_bool, transform=transforms.ToTensor(), download=True),\n",
        "      batch_size=batch_size, \n",
        "      shuffle=True)    \n",
        "  return data"
      ],
      "metadata": {
        "id": "k-zxO0mvS__m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(data_train, model, criterion, optimizer, epochs):\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    for data, targets in data_train:\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "      data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "      # forward\n",
        "      scores = model(data)\n",
        "      loss = criterion(scores, targets)\n",
        "\n",
        "      #backward\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ],
      "metadata": {
        "id": "93ngcsNO-bW_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def performance_metrics(model, dataset):\n",
        "  true_positives = [0]*10\n",
        "  false_negatives = [0]*10\n",
        "  false_positives = [0]*10\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data, targets in dataset:\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "      data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "      scores = model(data)\n",
        "      _, predicted = scores.max(1)\n",
        "\n",
        "      for i in range(targets.size()[0]):\n",
        "        actual_value = targets[i]\n",
        "        predicted_value = predicted[i]\n",
        "\n",
        "        if predicted_value == actual_value:\n",
        "          true_positives[actual_value] += 1\n",
        "        else:\n",
        "          false_negatives[actual_value] += 1\n",
        "          false_positives[predicted_value] += 1\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  #precision\n",
        "  precision = np.divide( true_positives, np.add(true_positives,false_positives) )\n",
        "  #recall\n",
        "  recall = np.divide( true_positives, np.add(true_positives,false_negatives) )\n",
        "  #F1 Score\n",
        "  F1_score = 2*np.divide( np.multiply(precision,recall), np.add(precision,recall) )\n",
        "\n",
        "  return precision, recall, F1_score"
      ],
      "metadata": {
        "id": "ye2NYH7itg-2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and evaluation of the Neural Network"
      ],
      "metadata": {
        "id": "zUnwvJ9rlr7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the data from the MNIST Dataset"
      ],
      "metadata": {
        "id": "nmhQuphGl4ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = LoadData(batch_size=64, train_bool=True)\n",
        "test_data = LoadData(batch_size=64, train_bool=False)"
      ],
      "metadata": {
        "id": "mf1im6HZURMB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training of the model"
      ],
      "metadata": {
        "id": "UICGHf3-mBbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNIST_NN(size_input=784, size_output=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train(train_data, model, criterion, optimizer, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpqdW7gHUWZL",
        "outputId": "f916dd8f-1343-45ff-c566-4fc731e4f5d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:01<00:00, 12.28s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing of the model"
      ],
      "metadata": {
        "id": "tQduLfCbmHVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, F1_score = performance_metrics(model,test_data)\n",
        "print(f'The performance of the model on the test data gives these averaged values: Precision: {np.mean(precision)*100:.2f}%, Recall: {np.mean(recall)*100:.2f}%, F1 score: {np.mean(F1_score):.4f}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KitX8x3yxYZs",
        "outputId": "a8895a68-a6e3-4263-ccdf-ca3a837aeca8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The performance of the model on the test data gives these averaged values: Precision: 97.88%, Recall: 97.84%, F1 score: 0.9786.\n"
          ]
        }
      ]
    }
  ]
}